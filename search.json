[{"path":"https://rachelesrogers.github.io/seqstrclean/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 seqstrclean authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/articles/larger_notecleaning.html","id":"hybrid-method","dir":"Articles","previous_headings":"","what":"Hybrid Method","title":"larger_notecleaning","text":"third method attempts combine speed First N Character method accuracy Longest Common Substring method. works first applying First N Character method, applying Longest Common Substring method difficult cases - either edit distance large First N Character method remove notes (chicken chasing example ), length cleaned notes unusually large. Unusually large defined set number standard deviations mean clean note length, calculated using extremeid function. method, larger dataset may necessary demonstrate presence outliers, terms note size. demonstrates validation dataset cleaned using First N Character method, character difference cutoff 16 (meaning including 15 character difference acceptable). example, method successfully applied (can seen comparing “notes” column cleaned “page_notes” column). However, notes clear-cut example . example , true value cleaned notes shown “corrected_notes” column. First N Character method fails case - edit distance (94) larger set threshold (16), notes removed. order determine extremely long note pages considered Longest Common Substring method, extremeid function applied. , extreme values defined larger 4 standard deviations mean page length, based condition dataframe (“algorithm”), resulted different information presented note-takers, thus providing different notes. comments considered using Longest Common Substring method extremely large amount notes (extreme_value=TRUE), edit distance cutoff used First N Character method (larger 15). Note previous page notes also necessary comparison Longest Common Substring method. Observations “apply_lcs” true indicate difficult cases. can run hybrid application lcs clean remaining notes. Due time, process completed single participant. notes show easy difficult case First N Character method (indicated “page_notes”). first row, FNC method able correctly distinguish old new notes. case, LCS need applied, FNC notes copied “hybrid_notes” column. second row, FNC method fails, leading application LCS. notes included “hybrid_notes” column, represents full dataset cleaned notes.","code":"library(kableExtra) library(dplyr) library(knitr)  fnc<-firstnchar(validation_dataset, \"notes\", 16, \"clean_prints\", \"page_count\")   fnc_printable <- fnc %>% slice(-1) %>% select(-c(algorithm,corrected_notes,clean_prints)) %>% head(3) fnc_printable <- purrr::map_df(fnc_printable, ~ gsub(\"[\\r\\n]\", \" \", .x)) #removing line breaks  fnc_printable %>% kable()%>%   kable_styling(font_size = 8) library(kableExtra) library(dplyr) library(knitr)  fnc<-firstnchar(validation_dataset, \"notes\", 16, \"clean_prints\", \"page_count\")   fnc_printable2 <- head(fnc %>% filter(clean_prints==39, page_count==12) %>% select(-c(algorithm,page_notes,clean_prints, page_count)), 1) fnc_printable2 <- purrr::map_df(fnc_printable2, ~ gsub(\"[\\r\\n]\", \" \", .x)) #removing line breaks  fnc_printable2 %>% kable()%>%   kable_styling(font_size = 8) extreme_dataset <- extremeid(dataset=fnc, extreme=4, clean_notes=\"page_notes\",                               pageid=\"page_count\", group_list = c(\"algorithm\"))  extreme_printable <- head(extreme_dataset %>% filter(extreme_value==TRUE, clean_prints==39) %>% subset(select=c(\"page_notes\", \"note_length\", \"outlier\", \"extreme_value\")), 1)  extreme_printable <- purrr::map_df(extreme_printable, ~ gsub(\"[\\r\\n]\", \" \", .x))  extreme_printable %>% kable()%>%   kable_styling(font_size = 8) extreme_dataset <- extreme_dataset %>% mutate(apply_lcs = ifelse(!is.na(edit_distance) & (extreme_value==TRUE | edit_distance > 15), TRUE, FALSE))  extreme_printable2 <- head(extreme_dataset %>% filter(apply_lcs==TRUE, clean_prints==39) %>% subset(select=c(\"page_notes\", \"edit_distance\", \"apply_lcs\")), 1)  extreme_printable2 <- purrr::map_df(extreme_printable2, ~ gsub(\"[\\r\\n]\", \" \", .x))  extreme_printable2 %>% kable()%>%   kable_styling(font_size = 8) hybrid_dataset <- lcsclean_hybrid(dataset=subset(extreme_dataset, clean_prints==39), notes=\"notes\", propor=0.333, identifier=\"clean_prints\", pageid=\"page_count\", toclean=\"apply_lcs\")  hybrid_printable1 <- head(hybrid_dataset[hybrid_dataset$apply_lcs==TRUE,] %>% subset(select=c(\"notes\", \"page_notes\", \"lcs_notes\", \"hybrid_notes\")), 1)  hybrid_printable2 <- head(hybrid_dataset[hybrid_dataset$apply_lcs==FALSE & !(hybrid_dataset$page_count %in% c(1,2)),] %>% subset(select=c(\"notes\", \"page_notes\", \"lcs_notes\", \"hybrid_notes\")), 1)  hybrid_printable <- rbind(hybrid_printable2,hybrid_printable1)  hybrid_printable <- purrr::map_df(hybrid_printable, ~ gsub(\"[\\r\\n]\", \" \", .x))  hybrid_printable %>% kable()%>%   kable_styling(font_size = 8)"},{"path":"https://rachelesrogers.github.io/seqstrclean/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Center Statistics Applications Forensic Evidence. Author, copyright holder, funder. Rachel Rogers. Author, maintainer. Susan VanderPlas. Author.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Center Statistics Applications Forensic Evidence, Rogers R, VanderPlas S (2024). seqstrclean: Sequential String Cleaning. R package version 0.0.0.9000, https://rachelesrogers.github.io/seqstrclean/, https://github.com/rachelesrogers/seqstrclean.","code":"@Manual{,   title = {seqstrclean: Sequential String Cleaning},   author = {{Center for Statistics and Applications in Forensic Evidence} and Rachel Rogers and Susan VanderPlas},   year = {2024},   note = {R package version 0.0.0.9000, https://rachelesrogers.github.io/seqstrclean/},   url = {https://github.com/rachelesrogers/seqstrclean}, }"},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"seqstrclean-","dir":"","previous_headings":"","what":"Sequential String Cleaning","title":"Sequential String Cleaning","text":"goal seqstrclean clean sequential strings. cumulative note taking, notes previous section may saved alongside notes current section. package aims remove previous section’s notes, leaving notes current section. example, person may take note: “cat ran tree.” initially, add “cat chased dog”. notepad show: “cat ran tree. cat chased dog”. package meant separate notes two parts based different saves notepad. firstnchar function compares beginning latest notes previous section, removes latest notes similar enough (determined edit distance). lcsclean function compares entirety note sheets locates longest common substring two, removed latest note sheet represents significant portion previous notes.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Sequential String Cleaning","text":"can install development version seqstrclean GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"rachelesrogers/seqstrclean\")"},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Sequential String Cleaning","text":"three methods used sequential note cleaning package: First N Character, Longest Common Substring, hybrid method combining two. First N Character method faster, small verification study Longest Common Substring method accurate. hybrid method strikes balance speed First N Character method accuracy Longest Common Substring method applying Longest Common Substring method difficult cases (previous text removed using First N Character method, supplied note sheet unusually long).","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"first-n-character-method","dir":"","previous_headings":"Example","what":"First N Character Method","title":"Sequential String Cleaning","text":"first method First N Character method, entirety previous page’s notes compared first n characters current page’s notes (n length previous page’s notes). notes similar enough (based edit distance), first n characters removed current page. test dataset shown , third note-takes (identified ID number), 2-3 pages notes. first individual wrote “”, “cat”, “ran” sequentially notes, one word per page. second individual wrote “” “dog” sequentially. third individual wrote “chicken chased” first page, “goat chased chicken” second page, reflect sequential note-taking. First N Character method can used separate notes, based written per page. , page_notes displays clean notes, edit_distance refers distance previous page notes first n character current page notes. cases sequential notes (individuals 1 2), edit distance 0, beginning notes match previous page’s notes. case third individual, edit distance 4 (four substitutions necessary change “goat” “chick”), greater set threshold 3. Thus, second page third individual’s notes include full text recorded second page (nothing removed).","code":"library(seqstrclean)  test_dataset <- data.frame(ID=c(\"1\",\"1\",\"2\",\"2\",\"1\", \"3\", \"3\"), Notes=c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\"), Page=c(1,2,1,2,3,1,2))  test_dataset #>   ID                       Notes Page #> 1  1                         The    1 #> 2  1                     The cat    2 #> 3  2                         The    1 #> 4  2                     The dog    2 #> 5  1                 The cat ran    3 #> 6  3      the chicken was chased    1 #> 7  3 The goat chased the chicken    2 fnc_app <- firstnchar(dataset=test_dataset,notes=\"Notes\",char_diff=3,identifier=\"ID\",pageid=\"Page\")  fnc_app #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17"},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"longest-common-substring-method","dir":"","previous_headings":"Example","what":"Longest Common Substring Method","title":"Sequential String Cleaning","text":"second method Longest Common Substring method, two page note strings compared entirity longest string common, certain threshold. longest string removed current page notes, process repeated longest common substring longer assigned cutoff. proportion threshold set 0.5, nothing removed third note taker’s second page, longest common substring (“chicken”) represents exactly half characters page. threshold lowered 0.49, “chicken” removed second page notes. represent removal longest common substring one iteration, next longest substring (“chased”) cutoff threshold. However, threshold reduced 0.25 (1/4 previous notes), “chased” removed second page notes well, leaving “goat” clean notes.","code":"lcsclean(test_dataset,\"Notes\",0.5,\"ID\",\"Page\") #>   ID                       Notes Page                  page_notes #> 1  1                         The    1                         The #> 2  1                     The cat    2                         cat #> 3  2                         The    1                         The #> 4  2                     The dog    2                         dog #> 5  1                 The cat ran    3                         ran #> 6  3      the chicken was chased    1      the chicken was chased #> 7  3 The goat chased the chicken    2 The goat chased the chicken lcsclean(test_dataset,\"Notes\",0.49,\"ID\",\"Page\") #>   ID                       Notes Page             page_notes #> 1  1                         The    1                    The #> 2  1                     The cat    2                    cat #> 3  2                         The    1                    The #> 4  2                     The dog    2                    dog #> 5  1                 The cat ran    3                    ran #> 6  3      the chicken was chased    1 the chicken was chased #> 7  3 The goat chased the chicken    2       The goat chased lcsclean(test_dataset,\"Notes\",0.25,\"ID\",\"Page\") #>   ID                       Notes Page             page_notes #> 1  1                         The    1                    The #> 2  1                     The cat    2                    cat #> 3  2                         The    1                    The #> 4  2                     The dog    2                    dog #> 5  1                 The cat ran    3                    ran #> 6  3      the chicken was chased    1 the chicken was chased #> 7  3 The goat chased the chicken    2              The goat"},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"hybrid-method","dir":"","previous_headings":"Example","what":"Hybrid Method","title":"Sequential String Cleaning","text":"hybrid method combines Longest Common Substring First N Character methods. First, First N Character method applied. cleaned notes First N Character method evaluated based two criteria: presence unusually long notes, presence notes larger edit distance First N Character method can handle. Unusually long notes identified [extremeid()] function: case, none notes extreme value, value two standard deviations mean note length given page. However, also want apply Longest Common Substring method edit distance large First N Character method handle (case, edit distance larger two): Based output , final line page notes suspect - edit distance larger can handled First N Character method. hybrid_notes column combines results First N Character method Longest Common Substring results, LCS method applied: resulting shorter text “goat” final entry.","code":"extreme_exam <- extremeid(dataset=fnc_app,clean_notes=\"page_notes\",extreme=2,pageid=\"Page\")  extreme_exam #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17 #>   note_length  outlier      mean       sd extreme_value #> 1           3 31.27264  9.333333 10.96966         FALSE #> 2           4 38.22478 11.666667 13.27906         FALSE #> 3           3 31.27264  9.333333 10.96966         FALSE #> 4           4 38.22478 11.666667 13.27906         FALSE #> 5           4       NA  4.000000       NA            NA #> 6          22 31.27264  9.333333 10.96966         FALSE #> 7          27 38.22478 11.666667 13.27906         FALSE library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  extreme_exam <- extreme_exam %>% mutate(apply_lcs = ifelse(!is.na(edit_distance) & (extreme_value==TRUE | edit_distance > 2), TRUE, FALSE))  extreme_exam #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17 #>   note_length  outlier      mean       sd extreme_value apply_lcs #> 1           3 31.27264  9.333333 10.96966         FALSE     FALSE #> 2           4 38.22478 11.666667 13.27906         FALSE     FALSE #> 3           3 31.27264  9.333333 10.96966         FALSE     FALSE #> 4           4 38.22478 11.666667 13.27906         FALSE     FALSE #> 5           4       NA  4.000000       NA            NA        NA #> 6          22 31.27264  9.333333 10.96966         FALSE     FALSE #> 7          27 38.22478 11.666667 13.27906         FALSE      TRUE hybrid_dataset <- lcsclean_hybrid(extreme_exam,\"Notes\",0.25,\"ID\",\"Page\", \"apply_lcs\")  hybrid_dataset #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17 #>   note_length  outlier      mean       sd extreme_value apply_lcs lcs_notes #> 1           3 31.27264  9.333333 10.96966         FALSE     FALSE      <NA> #> 2           4 38.22478 11.666667 13.27906         FALSE     FALSE      <NA> #> 3           3 31.27264  9.333333 10.96966         FALSE     FALSE      <NA> #> 4           4 38.22478 11.666667 13.27906         FALSE     FALSE      <NA> #> 5           4       NA  4.000000       NA            NA        NA      <NA> #> 6          22 31.27264  9.333333 10.96966         FALSE     FALSE      <NA> #> 7          27 38.22478 11.666667 13.27906         FALSE      TRUE The goat  #>             hybrid_notes #> 1                    The #> 2                    cat #> 3                    The #> 4                    dog #> 5                    ran #> 6 the chicken was chased #> 7              The goat"},{"path":"https://rachelesrogers.github.io/seqstrclean/index.html","id":"acknowledgements","dir":"","previous_headings":"","what":"Acknowledgements","title":"Sequential String Cleaning","text":"work funded (partially funded) Center Statistics Applications Forensic Evidence (CSAFE) Cooperative Agreements 70NANB15H176 70NANB20H019 NIST Iowa State University, includes activities carried Carnegie Mellon University, Duke University, University California Irvine, University Virginia, West Virginia University, University Pennsylvania, Swarthmore College University Nebraska, Lincoln.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/extremeid.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize Note Character Length — extremeid","title":"Summarize Note Character Length — extremeid","text":"Use identify extreme values, based cleaned note length, dataset. Can used applying firstnchar()","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/extremeid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize Note Character Length — extremeid","text":"","code":"extremeid(dataset, extreme, clean_notes, pageid, group_list = NA)"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/extremeid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize Note Character Length — extremeid","text":"dataset data frame notes extreme number standard deviations mean character length defines extreme value clean_notes column name clean notes provide summary values pageid column name page number group_list list variables group cleaned notes","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/extremeid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize Note Character Length — extremeid","text":"data frame","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/extremeid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize Note Character Length — extremeid","text":"","code":"test_dataset <- data.frame(ID=c(\"1\",\"1\",\"2\",\"2\",\"1\", \"3\",\"3\"), Notes=c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\"), Page=c(1,2,1,2,3,1,2)) cleaned_dataset<- firstnchar(dataset=test_dataset,notes=\"Notes\",char_diff=3, identifier=\"ID\",pageid=\"Page\") extremeid(dataset=cleaned_dataset,clean_notes=\"page_notes\",extreme=2,pageid=\"Page\") #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17 #>   note_length  outlier      mean       sd extreme_value #> 1           3 31.27264  9.333333 10.96966         FALSE #> 2           3 38.71281 11.000000 13.85641         FALSE #> 3           3 31.27264  9.333333 10.96966         FALSE #> 4           3 38.71281 11.000000 13.85641         FALSE #> 5           3       NA  3.000000       NA            NA #> 6          22 31.27264  9.333333 10.96966         FALSE #> 7          27 38.71281 11.000000 13.85641         FALSE"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/firstnchar.html","id":null,"dir":"Reference","previous_headings":"","what":"First N Character Note Cleaning — firstnchar","title":"First N Character Note Cleaning — firstnchar","text":"method note cleaning uses length previous notes compare beginning questioned page notes. enough correspondance two paes, notes removed current page.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/firstnchar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"First N Character Note Cleaning — firstnchar","text":"","code":"firstnchar(dataset, notes, char_diff, identifier, pageid)"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/firstnchar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"First N Character Note Cleaning — firstnchar","text":"dataset dataset containing notes notes column name notes char_diff allowable character difference removing notes identifier column name uniquely identifying identification pageid column name page number","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/firstnchar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"First N Character Note Cleaning — firstnchar","text":"data frame","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/firstnchar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"First N Character Note Cleaning — firstnchar","text":"","code":"test_dataset <- data.frame(ID=c(\"1\",\"1\",\"2\",\"2\",\"1\", \"3\", \"3\"), Notes=c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\"), Page=c(1,2,1,2,3,1,2)) firstnchar(dataset=test_dataset,notes=\"Notes\",char_diff=3,identifier=\"ID\",pageid=\"Page\") #>   ID                       Notes Page                  page_notes edit_distance #> 1  1                         The    1                         The            NA #> 2  1                     The cat    2                         cat             0 #> 3  2                         The    1                         The            NA #> 4  2                     The dog    2                         dog             0 #> 5  1                 The cat ran    3                         ran             0 #> 6  3      the chicken was chased    1      the chicken was chased            NA #> 7  3 The goat chased the chicken    2 The goat chased the chicken            17"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean.html","id":null,"dir":"Reference","previous_headings":"","what":"Longest Common Substring Note Cleaning — lcsclean","title":"Longest Common Substring Note Cleaning — lcsclean","text":"uses longest common substring method note cleaning, longest common substring two note pages identified removed longer set threshold.","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Longest Common Substring Note Cleaning — lcsclean","text":"","code":"lcsclean(dataset, notes, propor, identifier, pageid)"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Longest Common Substring Note Cleaning — lcsclean","text":"dataset dataset containing notes notes column name notes propor minimum necessary matching proportion previous notes removal identifier column name uniquely identifying identification pageid column name page number","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Longest Common Substring Note Cleaning — lcsclean","text":"data frame","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Longest Common Substring Note Cleaning — lcsclean","text":"","code":"test_dataset <- data.frame(ID=c(\"1\",\"1\",\"2\",\"2\",\"1\", \"3\",\"3\"), Notes=c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\"), Page=c(1,2,1,2,3,1,2)) lcsclean(test_dataset,\"Notes\",0.5,\"ID\",\"Page\") #>   ID                       Notes Page                  page_notes #> 1  1                         The    1                         The #> 2  1                     The cat    2                         cat #> 3  2                         The    1                         The #> 4  2                     The dog    2                         dog #> 5  1                 The cat ran    3                         ran #> 6  3      the chicken was chased    1      the chicken was chased #> 7  3 The goat chased the chicken    2 The goat chased the chicken"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean_hybrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","title":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","text":"function used apply longest common substring method extreme values dataset. used applying firstnchar() extremeid(). Dataset \"page_notes\" column corresponding cleaned notes outcome firstnchar().","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean_hybrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","text":"","code":"lcsclean_hybrid(dataset, notes, propor, identifier, pageid, toclean)"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean_hybrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","text":"dataset dataset containing notes notes column name notes propor minimum necessary matching proportion previous notes removal identifier column name uniquely identifying identification pageid column name page number toclean column name identifying column notes clean (TRUE/FALSE)","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean_hybrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","text":"data frame","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/lcsclean_hybrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Longest Common Substring Note Cleaning for Hybrid Method — lcsclean_hybrid","text":"","code":"test_dataset <- data.frame(ID=c(\"1\",\"1\",\"2\",\"2\",\"1\", \"3\",\"3\"), Notes=c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\"), Page=c(1,2,1,2,3,1,2), cleaning = c(FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, TRUE), page_notes = c(\"The\",\"The cat\",\"The\",\"The dog\",\"The cat ran\", \"the chicken was chased\", \"The goat chased the chicken\")) lcsclean_hybrid(test_dataset,\"Notes\",0.5,\"ID\",\"Page\", \"cleaning\") #>   ID                       Notes Page cleaning                  page_notes #> 1  1                         The    1    FALSE                         The #> 2  1                     The cat    2    FALSE                     The cat #> 3  2                         The    1    FALSE                         The #> 4  2                     The dog    2     TRUE                     The dog #> 5  1                 The cat ran    3    FALSE                 The cat ran #> 6  3      the chicken was chased    1    FALSE      the chicken was chased #> 7  3 The goat chased the chicken    2     TRUE The goat chased the chicken #>                     lcs_notes                hybrid_notes #> 1                        <NA>                         The #> 2                        <NA>                     The cat #> 3                        <NA>                         The #> 4                         dog                         dog #> 5                        <NA>                 The cat ran #> 6                        <NA>      the chicken was chased #> 7 The goat chased the chicken The goat chased the chicken"},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/validation_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Hybrid Method Validation Dataset — validation_dataset","title":"Hybrid Method Validation Dataset — validation_dataset","text":"subset participant responses Jury Perception study","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/validation_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hybrid Method Validation Dataset — validation_dataset","text":"","code":"validation_dataset"},{"path":[]},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/validation_dataset.html","id":"validation-dataset","dir":"Reference","previous_headings":"","what":"validation_dataset","title":"Hybrid Method Validation Dataset — validation_dataset","text":"data frame 561 rows 4 columns: clean_prints Identifier page_count page number notes uncleaned notes corrected_notes hand cleaned notes demonstrate correct format","code":""},{"path":"https://rachelesrogers.github.io/seqstrclean/reference/validation_dataset.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Hybrid Method Validation Dataset — validation_dataset","text":"Jury Perception Study (see Rogers (2024) https://digitalcommons.unl.edu/dissertations/AAI31240449/)","code":""}]
