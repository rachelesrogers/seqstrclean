---
title: "larger_notecleaning"
---

This article focuses on note cleaning for a larger data set.
While time-consuming, this code demonstrates the full application of this package, with a workable example of hybrid note cleaning.

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(seqstrclean)
```


### Hybrid Method

The third method attempts to combine the speed of the First N Character method with the accuracy of the Longest Common Substring method.
This works by first applying the First N Character method, then applying the Longest Common Substring method for difficult cases - either when the edit distance is too large for the First N Character method to remove notes (such as the chicken chasing example above), or when the length of the cleaned notes is unusually large.
Unusually large is defined as more than a set number of standard deviations above the mean clean note length, and is calculated using the extremeid function.

For this method, a larger dataset may be necessary to demonstrate the presence of outliers, in terms of note size.



```{r hybrid_dataset, warning=FALSE, message=FALSE}
library(kableExtra)
library(dplyr)
library(knitr)

fnc<-firstnchar(validation_dataset, "notes", 16, "clean_prints", "page_count")


fnc_printable <- fnc %>% slice(-1) %>% select(-c(algorithm,corrected_notes,clean_prints)) %>% head(3)
fnc_printable <- purrr::map_df(fnc_printable, ~ gsub("[\r\n]", " ", .x)) #removing line breaks

fnc_printable %>% kable()%>%
  kable_styling(font_size = 8)
```

Above demonstrates the validation dataset cleaned using the First N Character method, with a character difference cutoff of 16 (meaning that up to and including a 15 character difference is acceptable). 
In the above example, the method is successfully applied (as can be seen comparing the "notes" column to the cleaned "page_notes" column).

However, not all notes are as clear-cut as the example above.
For the example below, the true value of the cleaned notes should be as shown in the "corrected_notes" column.
The First N Character method fails in this case - because the edit distance (94) is larger than the set threshold (16), no notes would be removed.

```{r hybrid_dataset2, warning=FALSE, message=FALSE}
library(kableExtra)
library(dplyr)
library(knitr)

fnc<-firstnchar(validation_dataset, "notes", 16, "clean_prints", "page_count")


fnc_printable2 <- head(fnc %>% filter(clean_prints==39, page_count==12) %>% select(-c(algorithm,page_notes,clean_prints, page_count)), 1)
fnc_printable2 <- purrr::map_df(fnc_printable2, ~ gsub("[\r\n]", " ", .x)) #removing line breaks

fnc_printable2 %>% kable()%>%
  kable_styling(font_size = 8)
```

In order to determine if there are any extremely long note pages that should be considered for the Longest Common Substring method, the extremeid function is applied.
Here, extreme values are defined as those that are larger than 4 standard deviations above the mean page length, based on a condition in the dataframe ("algorithm"), which resulted in different information being presented to note-takers, thus providing different notes.


```{r hybrid_extreme}

extreme_dataset <- extremeid(dataset=fnc, extreme=4, clean_notes="page_notes", 
                             pageid="page_count", group_list = c("algorithm"))

extreme_printable <- head(extreme_dataset %>% filter(extreme_value==TRUE, clean_prints==39) %>% subset(select=c("page_notes", "note_length", "outlier", "extreme_value")), 1)

extreme_printable <- purrr::map_df(extreme_printable, ~ gsub("[\r\n]", " ", .x))

extreme_printable %>% kable()%>%
  kable_styling(font_size = 8)

```


The comments that should then be considered using the Longest Common Substring method are those with an extremely large amount of notes (extreme_value=TRUE), and those with an edit distance above the cutoff used in the First N Character method (larger than 15).
Note that the previous page of notes is also necessary for comparison in the Longest Common Substring method.

```{r rerun_id}

extreme_dataset <- extreme_dataset %>% mutate(apply_lcs = ifelse(!is.na(edit_distance) & (extreme_value==TRUE | edit_distance > 15), TRUE, FALSE))

extreme_printable2 <- head(extreme_dataset %>% filter(apply_lcs==TRUE, clean_prints==39) %>% subset(select=c("page_notes", "edit_distance", "apply_lcs")), 1)

extreme_printable2 <- purrr::map_df(extreme_printable2, ~ gsub("[\r\n]", " ", .x))

extreme_printable2 %>% kable()%>%
  kable_styling(font_size = 8)

```



Observations where "apply_lcs" is true indicate those difficult cases.
They can then be run through the hybrid application of lcs to clean the remaining notes. Due to time, this process was only completed on a single participant.


```{r lcs_hybrid}

hybrid_dataset <- lcsclean_hybrid(dataset=subset(extreme_dataset, clean_prints==39), notes="notes", propor=0.333, identifier="clean_prints", pageid="page_count", toclean="apply_lcs")

hybrid_printable1 <- head(hybrid_dataset[hybrid_dataset$apply_lcs==TRUE,] %>% subset(select=c("notes", "page_notes", "lcs_notes", "hybrid_notes")), 1)

hybrid_printable2 <- head(hybrid_dataset[hybrid_dataset$apply_lcs==FALSE & !(hybrid_dataset$page_count %in% c(1,2)),] %>% subset(select=c("notes", "page_notes", "lcs_notes", "hybrid_notes")), 1)

hybrid_printable <- rbind(hybrid_printable2,hybrid_printable1)

hybrid_printable <- purrr::map_df(hybrid_printable, ~ gsub("[\r\n]", " ", .x))

hybrid_printable %>% kable()%>%
  kable_styling(font_size = 8)

```

The above notes show an easy and a difficult case for the First N Character method (indicated as "page_notes").
In the first row, the FNC method is able to correctly distinguish between old and new notes.
In this case, LCS does not need to be applied, and the FNC notes are copied into the "hybrid_notes" column.
In the second row, the FNC method fails, leading to the application of LCS.
These notes are then included in the "hybrid_notes" column, so that this represents the full dataset of cleaned notes.
